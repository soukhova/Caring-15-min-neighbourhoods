# somewhat caring (0.2 to 6; total p50 7) - not complete (div=0.36; p50 0.40) (Cluster 3)
# not caring (0 to 4.7; total p50 3) - not complete (div=0.02; p50 0) (Cluster 5)
set.seed(5935)
# run the SOM algorithm
nrows <- 5
ncols <- 5
access.som <- trainSOM(x.data = access_15_wide |>
# Remove the non-normalized accessibility scores
select(-c(from_id, starts_with("total_"))),
dimension=c(nrows, ncols),
nb.save = 100,
radius.type = "letremy",
verbose = TRUE)
class(access.som)
summary(access.som)
plot(access.som,
what = "energy")
table(access.som$clustering)
plot(access.som,
what = "obs",
type = "hitmap")
par(mfrow=c(3,2))
plot(access.som,
what = "obs",
type = "color",
variable = 1,
show.names=TRUE,
main="norm_Dependent_centric")
plot(access.som,
what = "obs",
type = "color",
variable = 2,
show.names = TRUE,
main = "norm_Errand_centric")
plot(access.som,
what = "obs",
type = "color",
variable = 3,
show.names = TRUE,
main="norm_Grocery_centric")
plot(access.som,
what="obs",
type="color",
variable=4,
show.names = TRUE,
main="norm_Health_centric")
plot(access.som,
what="obs",
type="color",
variable = 9,
show.names = TRUE,
main="Diversity")
plot(access.som,
what = "obs",
type="barplot",
show.names=TRUE)
plot(access.som,
what="obs",
type="meanline",
key.loc=c(-2,8),
mar=c(0,2,2,0))
plot(access.som,
what="obs",
type="boxplot")
access.sc <- superClass(access.som,
k = 5)
summary(access.sc)
access_15_wide$cluster <- access.som$clustering
access_15_wide$scluster <- access.sc$cluster[access.som$clustering]
# transparentTheme(trans = .4)
# featurePlot(x = data.frame(access_15_wide$div,
#                            access_15_wide$Dependent_centric_norm,
#                            access_15_wide$Errand_centric_norm,
#                            access_15_wide$Grocery_centric_norm,
#                            access_15_wide$Health_centric_norm),
#             y = as.factor(access_15_wide$scluster),
#             plot = "pairs",
#             ## Add a key at the top
#             auto.key = list(columns = 8))
access_15_wide |>
select(scluster, starts_with("total_"), div) |>
group_by(scluster) |>
skim()
df <- access_15_wide |>
select(-c(cluster,
starts_with("prop"),
starts_with("norm"))) |>
rename(Dependent = total_Dependent_centric,
Grocery = total_Grocery_centric,
Errand = total_Errand_centric,
Health = total_Health_centric) |>
mutate(scluster = factor(scluster),
div = round(div, digits = 3))
df <- df |>
mutate(Total_copp = Dependent + Grocery + Errand + Health)
classmod.som <- rpart(data = df,
formula = scluster ~ (Dependent + Grocery + Errand + Health + div))
# Predict the labels and add them to the dataset
predicted_labels <- predict(classmod.som, df) |> as.data.frame()
df$SC1 <- predicted_labels$`1`
df$SC2 <- predicted_labels$`2`
df$SC3 <- predicted_labels$`3`
df$SC4 <- predicted_labels$`4`
df$SC5 <- predicted_labels$`5`
# df <- df |> mutate(max_label_val = pmax(predicted_labels$`1`, predicted_labels$`2`, predicted_labels$`3`, predicted_labels$`4`, predicted_labels$`5`),
#                    max_label = case_when(max_label_val == predicted_labels$`1` ~ "SC1",
#                                          max_label_val == predicted_labels$`2` ~ "SC2",
#                                          max_label_val == predicted_labels$`3` ~ "SC3",
#                                          max_label_val == predicted_labels$`4` ~ "SC4",
#                                          max_label_val == predicted_labels$`5` ~ "SC5"))
df_DA <- df |> left_join(access_15 |> dplyr::select(c("from_id","GeoUID")), by = "from_id") |>
group_by(GeoUID) |>
summarise(
SC1 = median(SC1),
SC2 = median(SC2),
SC3 = median(SC3),
SC4 = median(SC4),
SC5 = median(SC5),
max_label_val = pmax(SC1, SC2, SC3, SC4, SC5),
med_tot_copp_isc = median(Total_copp),
med_div = median(div),
med_dep_copp = median(Dependent),
med_err_copp = median(Errand),
med_groc_copp = median(Grocery),
med_health_copp = median(Health)) |>
mutate(max_label = case_when(max_label_val == SC1 ~ "b. Caring - complete (SC1)",
max_label_val == SC2 ~ "a. Very caring - very complete (SC2)",
max_label_val == SC3 ~ "d. Somewhat caring - not complete (SC3)",
max_label_val == SC4 ~ "c. Somewhat caring - complete (SC4)",
max_label_val == SC5 ~ "d. not caring - not complete (SC5)")) |>
left_join(HAM_census_21 |> select(c(GeoUID)), by=c("GeoUID")) |> st_as_sf() |> st_make_valid()
rpart.plot(classmod.som, cex = 0.5, type = 0, varlen = 8)
classmod.sompar <- as.party(classmod.som)
autoplot(classmod.sompar)
freq_sc <- ggplot(access_15_wide |>
mutate(scluster = factor(scluster))) +
geom_bar(aes(x = "",
group = scluster,
fill = scluster)) +
scale_fill_discrete(name = "Supercluster") #+
#theme_void() +
#guides(fill = guide_legend(nrow = 1)) +
#theme(legend.position = "bottom")
freq_sc
legd <- cowplot::get_legend(freq_sc)
legd
party_plot <- ggparty(classmod.sompar) +
geom_edge() +
geom_edge_label(size = 1.6) +
geom_node_label(aes(label = splitvar),
id = "inner",
size = 2, nudge_y = -0.022) +
# pass list to gglist containing all ggplot components we want to plot for each
# (default: terminal) node
geom_node_plot(gglist = list(geom_bar(aes(x = "", fill = scluster),
position = position_fill()),
xlab(""),
ylab(""),
theme_void(),
theme(axis.text = element_blank())))
party_plot
png(file= file.path(here("figures/decision_tree_profiles_sc.png")),width= 2404, height= 1600, units="px",  res=300)
plot_grid(party_plot, legd, nrow = 1, rel_widths = c(1, 0.2))
dev.off()
access_15_wide |>
select(scluster, starts_with("total_"), div) |>
rename_with(.fn = ~str_replace(.x, "total_", "")) |>
filter(scluster == 1) |>
skim()
df <- access_15_wide |>
transmute(scluster = factor(scluster),
Income_bottom = `v_CA21_1103: In bottom half of the distribution`/(`v_CA21_1103: In bottom half of the distribution` + `v_CA21_1121: In top half of the distribution`),
LICO = `v_CA21_1085: Prevalence of low income based on the Low-income cut-offs, after tax (LICO-AT) (%)`,
Avg_numb_of_kids = `v_CA21_498: Average number of children in census families with children`,
Not_in_labforce = `v_CA21_6504: Not in the labour force`/(`v_CA21_6498: Employed` + `v_CA21_6501: Unemployed` + `v_CA21_6504: Not in the labour force`),
Income_gini = `v_CA21_1142: Gini index on adjusted household after-tax income`,
Vis_minority = `v_CA21_4875: Total visible minority population`/ (`v_CA21_4914: Not a visible minority`+ `v_CA21_4875: Total visible minority population`),
Age_0to14 =(`v_CA21_11: 0 to 14 years`) / (`v_CA21_11: 0 to 14 years` + `v_CA21_68: 15 to 64 years` + `v_CA21_251: 65 years and over`),
One_parent_families = `v_CA21_507: Total one-parent families` / (`v_CA21_507: Total one-parent families` + `v_CA21_500: Total couple families`),
walk_towork =  `v_CA21_7647: Walked` / (`v_CA21_7647: Walked` + `v_CA21_7635: Car, truck or van` + `v_CA21_7644: Public transit` + `v_CA21_7650: Bicycle` + `v_CA21_7653: Other method` ),
Owner_hld_CHN = `v_CA21_4308: % in core housing need (57)`,
Hld_ownership = `v_CA21_4306: % of owner households with a mortgage (58)`,
Tenant_subsi_hld = `v_CA21_4314: % of tenant households in subsidized housing (61)`,
Tenant_hld_CHH =`v_CA21_4316: % in core housing need (57)`,
Population,
Low_or_no_deg = (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate`) / (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate` + `v_CA21_5874: Postsecondary certificate, diploma or degree`)
)
143882*4
View(access_15_aggregated)
new <- left_join(access_15_wide,
access_15_aggregated |> group_by(from_id) |>
summarise(GeoUID = first(GeoUID),
tot_copp_isc = first(tot_copp_isc),
Population = first(Population),
LICO = first(`v_CA21_1085: Prevalence of low income based on the Low-income cut-offs, after tax (LICO-AT) (%)`),
Income_bottom_n = first( `v_CA21_1103: In bottom half of the distribution`),
Income_top_n = first(`v_CA21_1121: In top half of the distribution`),
Age_0to14_n = first(`v_CA21_11: 0 to 14 years`),
Age_15to64_n = first(`v_CA21_68: 15 to 64 years`),
Age_65plus_n = first(`v_CA21_251: 65 years and over`),
One_parent_families_n = first(`v_CA21_507: Total one-parent families`),
Couple_families_n = first(`v_CA21_500: Total couple families`)),
by=c("from_id"))
View(access_15_aggregated)
View(access_15_wide)
df <- access_15_wide |> left_join(access_15_aggregated, by = "from_id") |>
df <- access_15_wide |> left_join(access_15_aggregated, by = "from_id") |>
transmute(scluster = factor(scluster),
Income_bottom = `v_CA21_1103: In bottom half of the distribution`/(`v_CA21_1103: In bottom half of the distribution` + `v_CA21_1121: In top half of the distribution`),
LICO = `v_CA21_1085: Prevalence of low income based on the Low-income cut-offs, after tax (LICO-AT) (%)`,
Avg_numb_of_kids = `v_CA21_498: Average number of children in census families with children`,
Not_in_labforce = `v_CA21_6504: Not in the labour force`/(`v_CA21_6498: Employed` + `v_CA21_6501: Unemployed` + `v_CA21_6504: Not in the labour force`),
Income_gini = `v_CA21_1142: Gini index on adjusted household after-tax income`,
Vis_minority = `v_CA21_4875: Total visible minority population`/ (`v_CA21_4914: Not a visible minority`+ `v_CA21_4875: Total visible minority population`),
Age_0to14 =(`v_CA21_11: 0 to 14 years`) / (`v_CA21_11: 0 to 14 years` + `v_CA21_68: 15 to 64 years` + `v_CA21_251: 65 years and over`),
One_parent_families = `v_CA21_507: Total one-parent families` / (`v_CA21_507: Total one-parent families` + `v_CA21_500: Total couple families`),
walk_towork =  `v_CA21_7647: Walked` / (`v_CA21_7647: Walked` + `v_CA21_7635: Car, truck or van` + `v_CA21_7644: Public transit` + `v_CA21_7650: Bicycle` + `v_CA21_7653: Other method` ),
Owner_hld_CHN = `v_CA21_4308: % in core housing need (57)`,
Hld_ownership = `v_CA21_4306: % of owner households with a mortgage (58)`,
Tenant_subsi_hld = `v_CA21_4314: % of tenant households in subsidized housing (61)`,
Tenant_hld_CHH =`v_CA21_4316: % in core housing need (57)`,
Population,
Low_or_no_deg = (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate`) / (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate` + `v_CA21_5874: Postsecondary certificate, diploma or degree`))
df <- access_15_wide |> left_join(access_15_aggregated, by = "from_id")
df <- access_15_wide |> left_join(access_15_aggregated, by = "from_id") |>
transmute(scluster = factor(scluster),
Income_bottom = `v_CA21_1103: In bottom half of the distribution`/(`v_CA21_1103: In bottom half of the distribution` + `v_CA21_1121: In top half of the distribution`),
LICO = `v_CA21_1085: Prevalence of low income based on the Low-income cut-offs, after tax (LICO-AT) (%)`,
Avg_numb_of_kids = `v_CA21_498: Average number of children in census families with children`,
Not_in_labforce = `v_CA21_6504: Not in the labour force`/(`v_CA21_6498: Employed` + `v_CA21_6501: Unemployed` + `v_CA21_6504: Not in the labour force`),
Income_gini = `v_CA21_1142: Gini index on adjusted household after-tax income`,
Vis_minority = `v_CA21_4875: Total visible minority population`/ (`v_CA21_4914: Not a visible minority`+ `v_CA21_4875: Total visible minority population`),
Age_0to14 =(`v_CA21_11: 0 to 14 years`) / (`v_CA21_11: 0 to 14 years` + `v_CA21_68: 15 to 64 years` + `v_CA21_251: 65 years and over`),
One_parent_families = `v_CA21_507: Total one-parent families` / (`v_CA21_507: Total one-parent families` + `v_CA21_500: Total couple families`),
walk_towork =  `v_CA21_7647: Walked` / (`v_CA21_7647: Walked` + `v_CA21_7635: Car, truck or van` + `v_CA21_7644: Public transit` + `v_CA21_7650: Bicycle` + `v_CA21_7653: Other method` ),
Owner_hld_CHN = `v_CA21_4308: % in core housing need (57)`,
Hld_ownership = `v_CA21_4306: % of owner households with a mortgage (58)`,
Tenant_subsi_hld = `v_CA21_4314: % of tenant households in subsidized housing (61)`,
Tenant_hld_CHH =`v_CA21_4316: % in core housing need (57)`,
Population,
Low_or_no_deg = (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate`) / (`v_CA21_5868: No certificate, diploma or degree` + `v_CA21_5871: High (secondary) school diploma or equivalency certificate` + `v_CA21_5874: Postsecondary certificate, diploma or degree`))
# examining correlations
cor(df |> select(-c("scluster")), use = "complete.obs")
#Train a decision tree using the data:
classdemo.som <- rpart(data = df,
formula = scluster ~ (Income_bottom + Age_0to14 + One_parent_families + Vis_minority + Not_in_labforce+ Income_gini+walk_towork+Owner_hld_CHN+Hld_ownership+Tenant_subsi_hld+Tenant_hld_CHH),
weights = Population
)
# convert the rpart object to a party object:
classdemo.sompar <- as.party(classdemo.som)
#Make a prettier plot:
party_plot <- ggparty(classdemo.sompar) +
geom_edge() +
#geom_edge_label(size = 1.8) +
geom_edge_label(mapping = aes(label = paste(substr(breaks_label, start = 1, stop = 15))), size = 3.5) +
geom_node_splitvar(id = "inner", size = 4) +
#geom_edge_label(mapping = aes(label = prettyNum(breaks_label, digits = 1)), size = 1.8) +
# # pass list to gglist containing all ggplot components we want to plot for each
# # (default: terminal) node
geom_node_plot(gglist = list(geom_bar(aes(x = "", fill = scluster),
position = position_fill()),
xlab(""),
ylab(""),
theme_void(),
theme(axis.text = element_blank())))
legd <- cowplot::get_legend(freq_sc)
#plot and save
png(file= file.path(here("figures/access_sc_profiles.png")),width= 2404, height= 1600, units="px",  res=300)
plot_grid(party_plot, legd, nrow = 1, rel_widths = c(1, 0.2))
dev.off()
#Train a decision tree using the data:
classdemo.som <- rpart(data = df,
formula = scluster ~ (Income_bottom + Age_0to14 + One_parent_families + Vis_minority + Not_in_labforce+ Income_gini+walk_towork+Owner_hld_CHN+Hld_ownership+Tenant_subsi_hld+Tenant_hld_CHH+LICO),
weights = Population
)
# convert the rpart object to a party object:
classdemo.sompar <- as.party(classdemo.som)
#Make a prettier plot:
party_plot <- ggparty(classdemo.sompar) +
geom_edge() +
#geom_edge_label(size = 1.8) +
geom_edge_label(mapping = aes(label = paste(substr(breaks_label, start = 1, stop = 15))), size = 3.5) +
geom_node_splitvar(id = "inner", size = 4) +
#geom_edge_label(mapping = aes(label = prettyNum(breaks_label, digits = 1)), size = 1.8) +
# # pass list to gglist containing all ggplot components we want to plot for each
# # (default: terminal) node
geom_node_plot(gglist = list(geom_bar(aes(x = "", fill = scluster),
position = position_fill()),
xlab(""),
ylab(""),
theme_void(),
theme(axis.text = element_blank())))
legd <- cowplot::get_legend(freq_sc)
#plot and save
png(file= file.path(here("figures/access_sc_profiles.png")),width= 2404, height= 1600, units="px",  res=300)
plot_grid(party_plot, legd, nrow = 1, rel_widths = c(1, 0.2))
dev.off()
rm(list=ls())
library(disk.frame)
library(cancensus)
library(sf)
library(leaflet)
library(r5r)
library(dplyr)
library(purrr)
setup_disk.frame()
# increase Java memory
options(java.parameters = "-Xmx6G")
#changing my time zone to Toronto's time zone
Sys.setenv(TZ='EDT')
list_census_regions('CA21') %>%
filter(level == "CSD", name %in% c("Hamilton"))
leaflet() |>
addTiles() |>
addPolygons(data= HAM_census_21, color = "green")
library(disk.frame)
library(cancensus)
library(sf)
library(leaflet)
library(r5r)
library(dplyr)
library(purrr)
setup_disk.frame()
# increase Java memory
options(java.parameters = "-Xmx6G")
#changing my time zone to Toronto's time zone
Sys.setenv(TZ='EDT')
load( file="HAM_census_21.rda")
care_dest <- read.csv("data-raw/FINAL_Care_Destinations_2023.csv")
care_dest <- st_as_sf(care_dest, coords = c("LONGITUDE", "LATITUDE"))
load( file="care_dest.rda")
dest <- care_dest
dest$lon <- st_coordinates(dest)[,1]
dest$lat <- st_coordinates(dest)[,2]
dest <- dest %>%
st_drop_geometry() %>%
transmute(ID = as.character(ID),
lon,
lat) %>%
rename("id" = "ID")
R_PARCELS_2020 <- st_read("data-raw/parcels/PED_LANDUSE_2020/PED_LANDUSE.shp") |> st_transform(st_crs(HAM_census_21)) |>
mutate(TYPE = ifelse(LUC1_DESCR == "Residential:Detached House" |
LUC1_DESCR == "Residential:Row/Town House"|
LUC1_DESCR == "Residential:Semi-Detached House" |
LUC1_DESCR == "Residential:Apartment (7 or more units)"|
LUC1_DESCR == "Residential:Multiplex Dwelling (6 units or less)"|
LUC1_DESCR == "Residential:Mobile Home",
"Residential", 0)) |>
filter(TYPE != 0)  #i.e. filter out non-residential
R_PARCELS_2020 <- st_make_valid(R_PARCELS_2020)
R_PARCELS_2020$ID <- 1:nrow(R_PARCELS_2020)
R_PARCELS_CENTS_2020 <- st_centroid(R_PARCELS_2020)
save("R_PARCELS_2020", file = "data-raw/parcels/R_PARCELS_2020.rda")
save("R_PARCELS_CENTS_2020", file = "data-raw/parcels/R_PARCELS_CENTS_2020.rda")
load( "data-raw/parcels/R_PARCELS_CENTS_2020.rda")
orig_sf <- R_PARCELS_CENTS_2020 |> st_as_sf()
rm(R_PARCELS_CENTS_2020,R_PARCELS_2020)
coords <- st_coordinates(orig_sf)
orig <- data.frame(id = orig_sf$ID,
lon = st_coordinates(orig_sf)[,1],
lat = st_coordinates(orig_sf)[,2])
rm(orig_sf)
# due to size, the calculation of travel times needs to be batched. We split the origins into 4 distinct dataframes.
orig_1 <- orig[1:36903,]
orig_2 <- orig[36904:73807,]
orig_3 <- orig[73808:110710,]
orig_4 <- orig[110711:143893,]
#check, make sure sums to 143893
nrow(orig_1)+nrow(orig_2)+nrow(orig_3)+nrow(orig_4)
#takesa few minutes
r5_HAM <- setup_r5(data_path = r5_path,  verbose = TRUE, elevation = "NONE")
# the r5r package requires Java Development Kit version 11, which can be downloaded from https://www.oracle.com/java/technologies/javase-jdk11-downloads.html . See the direction given in the r5r installation here (https://ipeagit.github.io/r5r/articles/r5r.html)
dir.create("./data-raw/tt") #create a folder, if it already exists - this function does nothing
r5_path <- file.path("./data-raw/tt")
list.files(r5_path)
#takesa few minutes
r5_HAM <- setup_r5(data_path = r5_path,  verbose = TRUE, elevation = "NONE")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(orig_1)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_1,
outdir = "parcel-ttm/processing/orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
origins = Orig_chunk,
destinations = dest,
mode = c("TRANSIT"),
departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
format = "%d-%m-%Y %H:%M:%S")),
max_trip_duration = 30)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "parcel-ttm/processing/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 6.78 minutes..."
ttm_care_TRANSIT_parcel1 <- as.data.frame(output_df)
save("ttm_care_TRANSIT_parcel1", file = "parcel-ttm/ttm_care_TRANSIT_parcel1.rda")
rm("ttm_care_TRANSIT_parcel1")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(orig_2)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_2,
outdir = "parcel-ttm/processing/orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
origins = Orig_chunk,
destinations = dest,
mode = c("TRANSIT"),
departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
format = "%d-%m-%Y %H:%M:%S")),
max_trip_duration = 30)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "parcel-ttm/processing/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 5.35 minutes..."
ttm_care_TRANSIT_parcel2 <- as.data.frame(output_df)
save("ttm_care_TRANSIT_parcel2", file = "parcel-ttm/ttm_care_TRANSIT_parcel2.rda")
rm("ttm_care_TRANSIT_parcel2")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(orig_3)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_3,
outdir = "parcel-ttm/processing/orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
origins = Orig_chunk,
destinations = dest,
mode = c("TRANSIT"),
departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
format = "%d-%m-%Y %H:%M:%S")),
max_trip_duration = 30)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "parcel-ttm/processing/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
ttm_care_TRANSIT_parcel3 <- as.data.frame(output_df)
save("ttm_care_TRANSIT_parcel3", file = "parcel-ttm/ttm_care_TRANSIT_parcel3.rda")
rm("ttm_care_TRANSIT_parcel3")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(orig_4)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_4,
outdir = "parcel-ttm/processing/orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
origins = Orig_chunk,
destinations = dest,
mode = c("TRANSIT"),
departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
format = "%d-%m-%Y %H:%M:%S")),
max_trip_duration = 30)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "parcel-ttm/processing/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 6.23 minutes..."
ttm_care_TRANSIT_parcel4 <- as.data.frame(output_df)
save("ttm_care_TRANSIT_parcel4", file = "parcel-ttm/ttm_care_TRANSIT_parcel4.rda")
rm("ttm_care_TRANSIT_parcel4")
