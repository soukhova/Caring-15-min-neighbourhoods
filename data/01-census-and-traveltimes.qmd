---
title: "01-census-and-traveltimes"
format: html
---

```{r}
rm(list=ls())
```

## Libraries and settings
```{r, message=FALSE}
library(disk.frame)
library(cancensus)
library(sf)
library(leaflet)
library(r5r)
library(dplyr)
library(purrr)

setup_disk.frame()
# increase Java memory
options(java.parameters = "-Xmx6G")
#changing my time zone to Toronto's time zone
Sys.setenv(TZ='EDT')
```


# Census data - for population characteristics (DA, their centroids for robustness checks, and census data)
Pulling data from {cancensus} for the Hamilton Census Subdivision (CSD) and various census variables at the level of the Dissemination Area (DA). We can see that the Hamilton CSD has a population of 569,353 and is identified by the CSD region id of "3525005". It is part of the CMA with ID 35537.
```{r}
list_census_regions('CA21') %>% 
  filter(level == "CSD", name %in% c("Hamilton"))
```

```{r, eval=FALSE}
HAM_census_21 <- get_census(dataset='CA21', 
                            regions=list(CSD="3525005"),
                            vectors=c("v_CA21_11", #total - aged 0-14
                                      "v_CA21_12", #males - aged 0-14
                                      "v_CA21_13", #females - aged 0-14
                                      "v_CA21_68", #total - aged 15-64
                                      "v_CA21_69", #males - aged 15-64
                                      "v_CA21_70", #females - aged 15-64
                                      "v_CA21_251", #total - aged 65 and over
                                      "v_CA21_252", #males - aged 65 and over
                                      "v_CA21_253", #females - aged 65 and over
                                      "v_CA21_1085", #total - prevalence of LICO-AT (%)
                                      "v_CA21_1086", #male - prevalence of LICO-AT (%)
                                      "v_CA21_1087",#female - prevalence of LICO-AT (%)
                                      "v_CA21_7647", #total - walked to work
                                      "v_CA21_7635", #total - drove or was driven to work
                                      "v_CA21_7644", #total - used transit to get to work
                                      "v_CA21_7650", #total - biked to work
                                      "v_CA21_7653" #total - used some other mode to get to work
                                      ), 
                                      level='DA', use_cache = FALSE, geo_format = 'sf', quiet = TRUE)

#NOTE: LICO-AF = "The Low‑income cut‑offs, after tax refer to income thresholds, defined using 1992 expenditure data, below which economic families or persons not in economic families would likely have devoted a larger share of their after‑tax income than average to the necessities of food, shelter and clothing. More specifically, the thresholds represented income levels at which these families or persons were expected to spend 20 percentage points or more of their after‑tax income than average on food, shelter and clothing. " 

#NOTE: the 'mode choice' is the count of the TOTAL population aged 15 years and over who is employed in the labour force.
```

Check:
```{r}
leaflet() |>
  addTiles() |>
  addPolygons(data= HAM_census_21, color = "green") 
```

Save DA census data (sf object, polygons) :
```{r, eval=FALSE}
save(HAM_census_21, file="HAM_census_21.rda")
```

# Care destinations
Load the *care destination* database that has been created and reformat it as a sf object:
```{r}
care_dest <- read.csv("data-raw/FINAL_Care_Destinations_2023.csv")

care_dest <- st_as_sf(care_dest, coords = c("LONGITUDE", "LATITUDE"))
```

Check:
```{r}
leaflet() |>
  addTiles() |>
  addMarkers(data= care_dest, popup = ~as.character(Name))
```

Save care destinations (sf object, points):
```{r}
save(care_dest, file="care_dest.rda")
#load( file="care_dest.rda")
```


# Modal-shed 15-minute travel time calculations (not used in the analysis)
Formatting origin (centroids of DAs (from_ids)) and destination (centroids of care destinations) points for the travel time calcs using r5r:
```{r}
load("HAM_census_21.rda")
Community_Boundaries <- read_sf("data-raw/boundaries/Community_Boundaries.shp") |> st_transform(st_crs(HAM_census_21))
City_Boundary <- read_sf("data-raw/boundaries/City_Boundary.shp") |> st_transform(st_crs(HAM_census_21))
```

```{r}
#some DAs are oddly shaped, such that their centroids are outside of their surface. here we create a function if the polygon has a centroid that is inside the polygon, use that, otherwise, find a point within the polygon. (From: https://stackoverflow.com/questions/52522872/r-sf-package-centroid-within-polygon)

st_centroid_within_poly <- function (poly) {

  # check if centroid is in polygon
  centroid <- poly %>% st_centroid() 
  in_poly <- st_within(centroid, poly, sparse = F)[[1]] 

  # if it is, return that centroid
  if (in_poly) return(centroid) 

  # if not, calculate a point on the surface and return that
  centroid_in_poly <- st_point_on_surface(poly) 
  return(centroid_in_poly)
}
```
```{r}
# orig_sf <- HAM_census_21 |> st_intersection(Community_Boundaries |> filter(COMMUNITY_ == "Dundas")) |>
#   mutate(lon = map_dbl(geometry, ~st_centroid_within_poly(.x)[[1]]),
#          lat = map_dbl(geometry, ~st_centroid_within_poly(.x)[[2]]))

orig_sf <- st_centroid_within_poly(HAM_census_21 |> st_intersection(Community_Boundaries |> filter(COMMUNITY_ == "Dundas")))

orig <- data.frame(id = orig_sf$GeoUID,
                   lon = st_coordinates(orig_sf)[,1],
                   lat = st_coordinates(orig_sf)[,2])

save(orig, file="HAM_census_21_centroids.rda")
```

## Setting up r5r core 

```{r set up r5 path, include=FALSE}
# the r5r package requires Java Development Kit version 11, which can be downloaded from https://www.oracle.com/java/technologies/javase-jdk11-downloads.html . See the direction given in the r5r installation here (https://ipeagit.github.io/r5r/articles/r5r.html)
dir.create("./data-raw/tt") #create a folder, if it already exists - this function does nothing

r5_path <- file.path("./data-raw/tt")
list.files(r5_path)
```

```{r download OSM street network, eval=FALSE}
# Specify the URL of the OSM file for Ontario - it takes a few minutes to download (~56MB)
download.file(url = "http://download.geofabrik.de/north-america/canada/ontario-latest.osm.pbf",
              destfile= file.path(r5_path, "Hamilton.osm.pbf"), mode = "wb")
#clip to the the hamilton city limits using OSM Convert .exe (). (NOTE: x = longitude)
osmdata::getbb("Hamilton")
```

```{r download GTFS data, eval=FALSE}
download.file(url = "https://transitfeeds.com/p/hamilton-street-railway/31/latest/download",
              destfile= file.path(r5_path, "HSR_transit.zip"), mode = "wb")
```

```{r build graph, eval = FALSE, cache=FALSE}
#takesa few minutes
r5_HAM <- setup_r5(data_path = r5_path,  verbose = TRUE, elevation = "NONE")
```

## Calculating the isocrones: DA centroids to care destinations 

Calculate **walk** 15-minute travel times from centroids of DAs (from_ids).
```{r walk travel time}
library(concaveman) #dundas works. Flamborough, hamilton, ancaster, stoney creek and Glanbrook DO NOT.
iso15_walk <- r5r::isochrone(r5r_core = r5_HAM,
                          origins = orig,
                          mode = "WALK",
                          sample_size = 1,
                          max_trip_duration = 60,
                          cutoffs = c(0,30, 60))

save("iso15_walk", file = "census-cent-ttm/iso15_walk.rda")
```

Check:
```{r}
# Mapping DAs #is weird 35250056
leaflet() |>
  addTiles() |>
  addPolygons(data = iso15_walk |> filter(id == 35250056)) |>
  addPolygons(data= HAM_census_21 |> filter(GeoUID == 35250056), color = "green") |>
  addMarkers(data = orig |> filter(id == 35250056) |> st_as_sf(coords = c("lon", "lat")))
```

```{r}
library(data.table)
library(ggplot2)
street_net <- street_network_to_sf(r5_HAM)
main_roads <- subset(street_net$edges)|>
                     #, street_class %like% 'PRIMARY|SECONDARY') 
                      st_intersection(Community_Boundaries |> filter(COMMUNITY_ == "Dundas"))
  
colors <- c('#ffe0a5','#ffcb69','#ffa600','#ff7c43','#f95d6a',
            '#d45087','#a05195','#665191','#2f4b7c','#003f5c')

ggplot() +
  geom_sf(data = iso15_walk |> filter(id == 35250056), aes(fill=factor(isochrone)), color = NA, alpha = .7) +
  geom_sf(data = main_roads, color = "black", size=0.01, alpha = 0.2) +
  geom_point(data = orig |> filter(id == 35250056), aes(x=lon, y=lat, color='DA centroids')) +
  scale_fill_manual(values = rev(colors) ) +
  scale_color_manual(values=c('DA centroids'='black')) +
  labs(fill = "Travel time\n(in minutes)", color='') +
  theme_minimal() +
  theme(axis.title = element_blank())
```

# Calculating travel time matrices: from DA centroids to care destinations, all modes
NOTE: in the future, compare these travel times to the population-weighted aggregated travel times. 
```{r}
dest <- care_dest

dest$lon <- st_coordinates(dest)[,1]
dest$lat <- st_coordinates(dest)[,2]

dest <- dest %>% 
  st_drop_geometry() %>%
  transmute(ID = as.character(ID),
            lon,
            lat) %>%
  rename("id" = "ID")
```

Calculate **car** travel times from centroids of DAs (from_ids) to destination points (to_ids). 60 min max travel time. 8am departure on a Tuesday. 30min +/- departure window. 
```{r car travel time, message=FALSE, eval=FALSE}
departure_datetime <- as.POSIXct("08-06-2023 08:00:00 EDT", # 12 GMT is 8am in Toronto
                                 format = "%d-%m-%Y %H:%M:%S")


start.time <- Sys.time()
ttm_care_car <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = orig,
                          destinations = dest,
                          mode = c("CAR"),
                          departure_datetime = departure_datetime,
                          time_window = 30,
                          percentiles = c(25,50,75),
                          max_trip_duration = 30,
                          verbose = TRUE)

end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_car <- as.data.frame(ttm_care_car)

save("ttm_care_car", file = "census-cent-ttm/ttm_care_car.rda")
```

Calculate **transit** travel times from centroids of DAs (from_ids) to destination points (to_ids). 60 min max travel time, 15 min max walking limit. 8am departure on a Tuesday. 30min +/- departure window.
```{r transit travel time}
departure_datetime <- as.POSIXct("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")


start.time <- Sys.time()
ttm_care_transit <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = orig,
                          destinations = dest,
                          mode = c("WALK", "TRANSIT"),
                          departure_datetime = departure_datetime,
                          time_window = 30,
                          percentiles = c(25,50,75),
                          max_trip_duration = 60,
                          max_walk_time = 15,
                          verbose = TRUE)

end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_transit <- as.data.frame(ttm_care_transit)

save("ttm_care_transit", file = "census-cent-ttm/ttm_care_transit.rda")
```

Calculate **walk** travel times from centroids of DAs (from_ids) to destination points (to_ids). 60 min max travel time, 15 min max walking limit. 8am departure on a Tuesday. 30min +/- departure window.
```{r walk travel time}
departure_datetime <- as.POSIXct("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")


start.time <- Sys.time()
ttm_care_walk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = orig,
                          destinations = dest,
                          mode = c("WALK"),
                          departure_datetime = departure_datetime,
                          time_window = 30,
                          percentiles = c(25,50,75),
                          max_trip_duration = 60,
                          verbose = TRUE)

end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_walk <- as.data.frame(ttm_care_walk)

save("ttm_care_walk", file = "census-cent-ttm/ttm_care_walk.rda")
```

Calculate **bike** travel times from centroids of DAs (from_ids) to destination points (to_ids). 60 min max travel time, 15 min max walking limit. 8am departure on a Tuesday. 30min +/- departure window.
```{r bike travel time}
departure_datetime <- as.POSIXct("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")


start.time <- Sys.time()
ttm_care_bike <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = orig,
                          destinations = dest,
                          mode = c("BICYCLE"),
                          departure_datetime = departure_datetime,
                          time_window = 30,
                          percentiles = c(25,50,75),
                          max_trip_duration = 60,
                          verbose = TRUE)

end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_bike <- as.data.frame(ttm_care_bike)

save("ttm_care_bike", file = "census-cent-ttm/ttm_care_bike.rda")
```

Limitations of travel time calcs:
- does not consider traffic stress (i.e., car, bike, and walk for all percentiles are identical -- the time window does not matter and no traffic is assumed)
- for transit, the time window accounts for departures +/- 30 minutes. This accounts for transit availability variability but also does not accont for traffic stress

# Calculating travel time matrices: from parcel centroids to care destinations (this is used in the analysis!)

```{r}
load( file="care_dest.rda")
dest <- care_dest

dest$lon <- st_coordinates(dest)[,1]
dest$lat <- st_coordinates(dest)[,2]

dest <- dest %>% 
  st_drop_geometry() %>%
  transmute(ID = as.character(ID),
            lon,
            lat) %>%
  rename("id" = "ID")
```

```{r, eval=FALSE}
R_PARCELS_2020 <- st_read("data-raw/parcels/PED_LANDUSE_2020/PED_LANDUSE.shp") |> st_transform(st_crs(HAM_census_21)) |>
  mutate(TYPE = ifelse(LUC1_DESCR == "Residential:Detached House" | 
                         LUC1_DESCR == "Residential:Row/Town House"| 
                         LUC1_DESCR == "Residential:Semi-Detached House" |
                         LUC1_DESCR == "Residential:Apartment (7 or more units)"|
                         LUC1_DESCR == "Residential:Multiplex Dwelling (6 units or less)"|
                         LUC1_DESCR == "Residential:Mobile Home",
                       "Residential", 0)) |>
  filter(TYPE != 0)  #i.e. filter out non-residential

R_PARCELS_2020 <- st_make_valid(R_PARCELS_2020)

R_PARCELS_2020$ID <- 1:nrow(R_PARCELS_2020)

R_PARCELS_CENTS_2020 <- st_centroid(R_PARCELS_2020)
save("R_PARCELS_2020", file = "data-raw/parcels/R_PARCELS_2020.rda")
save("R_PARCELS_CENTS_2020", file = "data-raw/parcels/R_PARCELS_CENTS_2020.rda")
```

```{r}
load( "data-raw/parcels/R_PARCELS_CENTS_2020.rda")

orig_sf <- R_PARCELS_CENTS_2020 |> st_as_sf()
rm(R_PARCELS_CENTS_2020,R_PARCELS_2020)

coords <- st_coordinates(orig_sf)
orig <- data.frame(id = orig_sf$ID,
                   lon = st_coordinates(orig_sf)[,1],
                   lat = st_coordinates(orig_sf)[,2])

rm(orig_sf)
```
```{r}
# due to size, the calculation of travel times needs to be batched. We split the origins into 4 distinct dataframes.

orig_1 <- orig[1:36903,]
orig_2 <- orig[36904:73807,]
orig_3 <- orig[73808:110710,]
orig_4 <- orig[110711:143893,]

#check, make sure sums to 143893
nrow(orig_1)+nrow(orig_2)+nrow(orig_3)+nrow(orig_4)
```

## Walk travel times

Calculate **walk** travel times from centroids of parcels (from_ids) to destination points (to_ids). 30 min max travel time. 

```{r walk travel time 1}
# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_1)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_1,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 6.78 minutes..."
ttm_care_walk_parcel1 <- as.data.frame(output_df)

save("ttm_care_walk_parcel1", file = "parcel-ttm/ttm_care_walk_parcel1.rda")
rm("ttm_care_walk_parcel1")
```

```{r walk travel time 2}
# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_2)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_2,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 5.35 minutes..."
ttm_care_walk_parcel2 <- as.data.frame(output_df)

save("ttm_care_walk_parcel2", file = "parcel-ttm/ttm_care_walk_parcel2.rda")
rm("ttm_care_walk_parcel2")
```

```{r walk travel time 3}
# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_3)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_3,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_walk_parcel3 <- as.data.frame(output_df)

save("ttm_care_walk_parcel3", file = "parcel-ttm/ttm_care_walk_parcel3.rda")
rm("ttm_care_walk_parcel3")
```

```{r walk travel time 4}
# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_4)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_4,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 6.23 minutes..."

ttm_care_walk_parcel4 <- as.data.frame(output_df)

save("ttm_care_walk_parcel4", file = "parcel-ttm/ttm_care_walk_parcel4.rda")
rm("ttm_care_walk_parcel4")
```

## Bike travel times

Calculate **bike** travel times from centroids of parcels (from_ids) to destination points (to_ids). 30 min max travel time. 8am departure on a Tuesday.
Calculate **bike** travel times from centroids of parcels (from_ids) to destination points (to_ids). 30 min max travel time. 
```{r bike travel time 1}
# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_1)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_1,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("BICYCLE"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 6.78 minutes..."
ttm_care_bike_parcel1 <- as.data.frame(output_df)

save("ttm_care_bike_parcel1", file = "parcel-ttm/ttm_care_bike_parcel1.rda")
rm("ttm_care_bike_parcel1")

# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_2)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_2,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("BICYCLE"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
#"OD matrix calculation took 5.35 minutes..."
ttm_care_bike_parcel2 <- as.data.frame(output_df)

save("ttm_care_bike_parcel2", file = "parcel-ttm/ttm_care_bike_parcel2.rda")
rm("ttm_care_bike_parcel2")

# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_3)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_3,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("BICYCLE"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_bike_parcel3 <- as.data.frame(output_df)

save("ttm_care_bike_parcel3", file = "parcel-ttm/ttm_care_bike_parcel3.rda")
rm("ttm_care_bike_parcel3")

# set up batching according to how many origin rows to process at one time
chunksize = 50 
num_chunks = ceiling(nrow(orig_4)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(orig_4,
                          outdir = "parcel-ttm/processing/orig",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  Orig_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5r_core = r5_HAM,
                          origins = Orig_chunk,
                          destinations = dest,
                          mode = c("BICYCLE"),
                          departure_datetime = as.POSIXct(strptime("08-06-2023 08:00:00", # 12 GMT is 8am in Toronto (EDT)
                                 format = "%d-%m-%Y %H:%M:%S")),
                          max_trip_duration = 30)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "parcel-ttm/processing/output_ttm",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))

ttm_care_bike_parcel4 <- as.data.frame(output_df)

save("ttm_care_bike_parcel4", file = "parcel-ttm/ttm_care_bike_parcel4.rda")
rm("ttm_care_bike_parcel4")
```

Limitations of travel time calcs:
- does not consider traffic stress (i.e., car, bike, and walk for all percentiles are identical -- the time window does not matter and no traffic is assumed)
- for transit, the time window accounts for departures +/- 30 minutes. This accounts for transit availability variability but also does not accont for traffic stress

INSPECTING:
```{r}
# library(data.table)
# library(ggplot2)
# street_net <- street_network_to_sf(r5_HAM)
# main_roads_all <- street_net$edges |> subset(street_class %like% 'PRIMARY|SECONDARY')
#   
# colors <- c('#ffe0a5','#ffcb69','#ffa600','#ff7c43','#f95d6a',
#             '#d45087','#a05195','#665191','#2f4b7c','#003f5c')
# 
# ggplot() +
#   geom_sf(data = main_roads_all, color = "black", size=0.01, alpha = 0.2) +
#   #geom_point(data = orig, aes(x=lon, y=lat, color='Parcel centroids')) +
#   geom_sf(data = Community_Boundaries, col="yellow", size = 0.01, alpha = 0.2)+
#   theme_minimal() +
#   theme(axis.title = element_blank())
```
